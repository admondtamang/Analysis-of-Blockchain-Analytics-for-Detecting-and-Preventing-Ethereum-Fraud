{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0CFJAcTlTh9ZPM7MGM62m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/admondtamang/Analysis-of-Blockchain-Analytics-for-Detecting-and-Preventing-Ethereum-Fraud/blob/main/thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WbqCvD3ZvhK2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    precision_recall_fscore_support,\n",
        "    accuracy_score\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- 1. Data Loading ---\n",
        "file_path = 'transaction_dataset.csv'\n",
        "try:\n",
        "    df = pd.read_csv(file_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{file_path}' was not found. Please check the file path.\")\n",
        "    exit()\n",
        "\n",
        "print(\"--- Initial Data Head ---\")\n",
        "print(df.head())\n",
        "print(\"\\n--- Initial Data Description ---\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "rUXoXUzl-egK",
        "outputId": "fdf8b356-e437-4005-8dc0-f434e79fd4fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: The file 'transaction_dataset.csv' was not found. Please check the file path.\n",
            "--- Initial Data Head ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b33e698f0286>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- Initial Data Head ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--- Initial Data Description ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- 2. Initial Cleaning & Preprocessing ---\n",
        "print(\"\\n--- Starting Preprocessing ---\")\n",
        "\n",
        "# Drop irrelevant index-like columns\n",
        "if 'Unnamed: 0' in df.columns:\n",
        "    df = df.drop(columns=['Unnamed: 0'])\n",
        "if 'Index' in df.columns:\n",
        "    df = df.drop(columns=['Index'])\n",
        "\n",
        "# Strip whitespace from column names\n",
        "df.columns = df.columns.str.strip()\n",
        "print(\"\\nColumn names stripped.\")\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "if 'FLAG' not in df.columns:\n",
        "    print(\"Error: Target column 'FLAG' not found in the dataset.\")\n",
        "    exit()\n",
        "X = df.drop(columns=['FLAG'])\n",
        "y = df['FLAG']\n",
        "\n",
        "# Drop 'Address' column and categorical ERC20 token type columns\n",
        "columns_to_drop_explicitly = ['Address', 'ERC20 most sent token type', 'ERC20_most_rec_token_type']\n",
        "for col in columns_to_drop_explicitly:\n",
        "    if col in X.columns:\n",
        "        X = X.drop(columns=[col])\n",
        "        print(f\"Dropped column: {col}\")\n",
        "\n",
        "# Impute remaining missing values in features with 0\n",
        "X.fillna(0, inplace=True)\n",
        "print(\"\\nMissing values in features imputed with 0.\")\n",
        "\n",
        "# Identify and drop zero-variance columns (after imputation)\n",
        "# These were identified as problematic from EDA (e.g., ERC20 avg time columns, ERC20 contract value columns)\n",
        "# A more robust way is to check variance:\n",
        "cols_before_variance_drop = X.shape[1]\n",
        "variances = X.var()\n",
        "zero_variance_cols = variances[variances == 0].index.tolist()\n",
        "\n",
        "if zero_variance_cols:\n",
        "    X = X.drop(columns=zero_variance_cols)\n",
        "    print(f\"\\nDropped {len(zero_variance_cols)} zero-variance columns: {zero_variance_cols}\")\n",
        "    print(f\"Number of features remaining: {X.shape[1]}\")\n",
        "else:\n",
        "    print(\"\\nNo zero-variance columns found to drop.\")"
      ],
      "metadata": {
        "id": "-ardGs24-q2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Feature Scaling ---\n",
        "# Select only numeric columns for scaling (should be all at this point if object columns were handled)\n",
        "numeric_cols = X.select_dtypes(include=np.number).columns\n",
        "scaler = MinMaxScaler()\n",
        "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
        "print(\"\\nNumerical features scaled using MinMaxScaler.\")\n",
        "print(\"\\n--- Preprocessed Features Head ---\")\n",
        "print(X.head())\n"
      ],
      "metadata": {
        "id": "cXhXo9-J-tV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- 4. Train-Test Split ---\n",
        "# Stratify by y to ensure proportional representation of classes\n",
        "try:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "    print(f\"\\nData split into training and testing sets.\")\n",
        "    print(f\"Training set shape: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "    print(f\"Testing set shape: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "    print(f\"Fraud cases in training set: {sum(y_train)}\")\n",
        "    print(f\"Fraud cases in testing set: {sum(y_test)}\")\n",
        "except ValueError as e:\n",
        "    print(f\"Error during train-test split. This might happen if features are not purely numeric: {e}\")\n",
        "    print(\"Ensure all features in X are numeric before splitting.\")\n",
        "    exit()\n"
      ],
      "metadata": {
        "id": "QV-D67kx-y5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- 5. Model Training and Evaluation ---\n",
        "print(\"\\n--- Starting Model Training and Evaluation ---\")\n",
        "\n",
        "# Define models\n",
        "# For imbalanced datasets, class_weight='balanced' or scale_pos_weight can be helpful.\n",
        "# scale_pos_weight = count(negative instances) / count(positive instances)\n",
        "neg_count = y_train.value_counts()[0]\n",
        "pos_count = y_train.value_counts()[1]\n",
        "scale_pos_weight_val = neg_count / pos_count\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(solver='liblinear', class_weight='balanced', random_state=42, max_iter=1000),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', scale_pos_weight=scale_pos_weight_val, random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "trained_models = {}\n",
        "\n",
        "plt.figure(figsize=(10, 8)) # For ROC curves\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n--- Training {model_name} ---\")\n",
        "    model.fit(X_train, y_train)\n",
        "    trained_models[model_name] = model\n",
        "\n",
        "    print(f\"\\n--- Evaluating {model_name} ---\")\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary', pos_label=1)\n",
        "    auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "    results[model_name] = {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision (Fraud)\": precision,\n",
        "        \"Recall (Fraud)\": recall,\n",
        "        \"F1-Score (Fraud)\": f1,\n",
        "        \"AUC-ROC\": auc_roc\n",
        "    }\n",
        "\n",
        "    print(f\"Results for {model_name}:\")\n",
        "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"  Precision (Fraud): {precision:.4f}\")\n",
        "    print(f\"  Recall (Fraud): {recall:.4f}\")\n",
        "    print(f\"  F1-Score (Fraud): {f1:.4f}\")\n",
        "    print(f\"  AUC-ROC: {auc_roc:.4f}\")\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['Non-Fraud (0)', 'Fraud (1)']))\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(cm)\n",
        "    plt.figure(figsize=(6,4)) # New figure for each CM\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Fraud', 'Fraud'], yticklabels=['Non-Fraud', 'Fraud'])\n",
        "    plt.title(f'Confusion Matrix - {model_name}')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.show() # Show CM plot immediately\n",
        "\n",
        "    # For collective ROC curve plot\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc_roc:.2f})')\n",
        "\n",
        "# Finalize collective ROC curve plot\n",
        "plt.plot([0, 1], [0, 1], 'k--') # Diagonal dashed line\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curves')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n--- Model Performance Summary ---\")\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "6BWGXaLm-2yD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- 6. Feature Importance ---\n",
        "print(\"\\n--- Feature Importance Analysis ---\")\n",
        "\n",
        "# Random Forest\n",
        "if \"Random Forest\" in trained_models:\n",
        "    rf_model = trained_models[\"Random Forest\"]\n",
        "    importances_rf = rf_model.feature_importances_\n",
        "    feature_names = X_train.columns\n",
        "    forest_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(x=forest_importances.head(20), y=forest_importances.head(20).index) # Display top 20\n",
        "    plt.title('Top 20 Feature Importances - Random Forest')\n",
        "    plt.xlabel('Mean decrease in impurity')\n",
        "    plt.ylabel('Feature')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(\"\\nTop 10 Features (Random Forest):\")\n",
        "    print(forest_importances.head(10))\n",
        "\n",
        "# XGBoost\n",
        "if \"XGBoost\" in trained_models:\n",
        "    xgb_model = trained_models[\"XGBoost\"]\n",
        "    importances_xgb = xgb_model.feature_importances_\n",
        "    xgb_importances = pd.Series(importances_xgb, index=feature_names).sort_values(ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(x=xgb_importances.head(20), y=xgb_importances.head(20).index) # Display top 20\n",
        "    plt.title('Top 20 Feature Importances - XGBoost')\n",
        "    plt.xlabel('Feature Importance Score (e.g., gain)')\n",
        "    plt.ylabel('Feature')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(\"\\nTop 10 Features (XGBoost):\")\n",
        "    print(xgb_importances.head(10))\n",
        "\n",
        "print(\"\\n--- Analysis Complete ---\")"
      ],
      "metadata": {
        "id": "Tkf9x-wW-20m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}